---
title: "__Temporal Overlap Analyses of Tropical Arctiidae Species__"
author: "Jonas Geschke and Sören Greule"
date: "Winter semester 2015/16"
output:
  pdf_document:
    toc: yes
documentclass: article
classoption: a4paper
---



- - - - - - - - - -
# Introduction
_This skript is the outcome of a selected topic within the MSc Environmental Scienes, Faculty of Environment and Natural Resources, University of Freiburg. The selected topic is supervised by Dr Tim Burzlaff._

The script is about the analysis of monitoring data from both Costa Rica (locations: El Bosque Nuevo Butterfly Farm and the private home of P. Gloor, near San José) and Peru (location: Panguana). The main interest is about looking for existing temporal niche and community interactions within species of Arctiinae and Ithomiini species.



- - - - - - - - - -
# Methodology: Technical Thinking Process

1. co-occurrence approach => not really good results, need to specify actual research question and thereby subsettings of the data => WORKS NO
2. found paper (mentioned above) => niche overlap approach

The main analysis approach comes from the paper "Temporal Overlap and Co-Occurrence in a Guild of Sub-Tropical Tephritid Fruit Flies" by Lopes GN, Souza-Filho MF, Gotelli NJ, Lemos LJU, Godoy WAC and Zucchi RA (2015) in PLoS ONE 10(7): e0132124, [doi:10.1371/journal.pone.0132124](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132124). We concentrate on their idea about the niche overlap analyses.

3. Pianka and Czekanowski => only indices, so edit of the background formular that it fits our needs => WORKS YES
4. ROSARIO: works with looping time periods (one year, one day) => we dont have proper data => WORKS NO
5. RA3: null-model approach, which randomized also the null values => transforms our data into pseudo-data => WORKS NO
6. RA4: null-model apporach, which fixes null values and randomizes the others => WORKS YES
7. run XXX RA4 randomized datasheets for Pianka/Czekanowski analysis as null-model approach of our temporal overlap apporach
8. run power-test on how many randomized iterations we actually need
9. t-test


The data used in our analyses come from the long-term monitoring trapping of the Chair of Forest Zoology and Entomology, University of Freiburg, and was undertaken by several staff members and student assistants.



# Steps within statistical analysis

1. Revising original data and re-organizing it for easier processing
2. Creating cast_"site" datasets as input for niche overlap analyses
    => cast_site function, input: Gdata
3. Run of observation datasets
    => RA4_nicheoverlap function, ra4 = FALSE, txt = FALSE, input: results of 2
4. Extracting the species with overlap probability of at least 0.75 in at least one spp pair
    => spppairs75prob function, input: reults of 3
5. Run of randomized datasets, only with 0.75prob species
    => RA4_nicheoverlap function, ra4 = TRUE, txt = TRUE, input: results of 4
6. Merge results, if needed
    => readin function, input: results of 5
7. t-test



- - - - - - - - - -
# Script

## Defining general settings

In here, we set the working directory, which one might have to adapt or change in order to get this skript running. Further, we provide the code for installing all needed packages and activate them.

```{r, message=FALSE}
# Setting the working directory
setwd("~/Studium/MSc/3. Semester/Temporal_niche_analyses/Git")

# Installing packages if needed
if("lubridate" %in% rownames(installed.packages())  == FALSE) {install.packages("lubridate")}
if("ggplot2" %in% rownames(installed.packages())    == FALSE) {install.packages("ggplot2")}
if("reshape" %in% rownames(installed.packages())    == FALSE) {install.packages("reshape")}
if("EcoSimR" %in% rownames(installed.packages())    == FALSE) {install.packages("EcoSimR")}
if("pwr" %in% rownames(installed.packages())        == FALSE) {install.packages("pwr")}

# Loading packages
library(lubridate)
library(ggplot2)
library(reshape)
library(EcoSimR)
library(pwr)
```


## Revising the original data

Now we read the original data and directly resave it as an archive datafile. In the working datafile `Gdata`, we rename the columns for easier handling.

```{r, results='hide'}
# Load the original datatable
Gdata <- read.csv2("IndID Auszug 01.Sep 15 All In.csv",
                   header = T,
                   sep = ";",
                   na.strings = "")

# Resaving original datatable as archive table
GdataORIG <- Gdata

# Show original column names
names(Gdata)

# Renaming columns
names(Gdata)[names(Gdata) == "DataSet"]     <- "taxon"
names(Gdata)[names(Gdata) == "Bemerkung1"]  <- "notes"
names(Gdata)[names(Gdata) == "day_night"]   <- "light"
names(Gdata)[names(Gdata) == "Art."]        <- "spp"
names(Gdata)[names(Gdata) == "FangDatum"]   <- "date"
names(Gdata)[names(Gdata) == "FangOrt"]     <- "site"
names(Gdata)[names(Gdata) == "FangZeit"]    <- "time"
names(Gdata)[names(Gdata) == "IndID"]       <- "iid"
names(Gdata)[names(Gdata) == "Sex"]         <- "sex"
names(Gdata)[names(Gdata) == "Typ1"]        <- "trap"
names(Gdata)[names(Gdata) == "Vertrauen"]   <- "trust"

# Control new column names
names(Gdata)
```


Now, we have a table that we can further process.
First of all, we do not need the columns "notes" and "iid" (individual ID) and correct some oversight mistakes within the datatable. Also, we do have 2 levels of trust within the whole datatable - 1 and 2. Trust level "2" is good, level "1" not so much. Those datapoint with no trust level at all are deleted at once.

```{r, results='hide'}
# Deleting the "notes" and "iid" columns
Gdata$notes <- NULL
Gdata$iid <- NULL
names(Gdata)

# Delete all rows, where the trust level is equal 0 (= NA)
Gdata <- subset(Gdata, Gdata$trust != "NA")
Gdata <- droplevels(Gdata)
summary(Gdata)

# Correcting the "light" cells
summary(Gdata$light)
Gdata$light[Gdata$light == "atg"]           <- "tag"
Gdata$light[Gdata$light == "tag "]          <- "tag"
Gdata$light[Gdata$light == "nacht\n"]       <- "nacht"
Gdata$light[Gdata$light == "nachts"]        <- "nacht"
Gdata <- droplevels(Gdata)
summary(Gdata$light)
### There are further values we need to think about! ("m" and time)

# Correcting the "site" cells
summary(Gdata$site)
Gdata$site[Gdata$site == "CR"]              <- "EBN"
Gdata$site[Gdata$site == "EBN\n"]           <- "EBN"
Gdata$site[Gdata$site == "GLOOR"]           <- "PG"
Gdata <- droplevels(Gdata)
summary(Gdata$site)

# Correcting the "sex" cells
summary(Gdata$sex)
Gdata$sex[Gdata$sex == "f "]                <- "f"
Gdata$sex[Gdata$sex == "w"]                 <- "f"
Gdata <- droplevels(Gdata)
summary(Gdata$sex)
### There are further values we need to think about! ("?" and "f?")
```


## Processing the data for further uses

For getting an overview plot of our data, we sort the whole datatable by date. Thus, we add two columns. Each one for the year and for the month. Afterwards we would like to produce a first plot, so we also add two columns containing information about the month and the day number.

```{r, results='hide'}
# Creating the column "year"
Gdata <- cbind(Gdata, "year" = format(as.Date(Gdata$date, "%d.%m.%Y"), "%Y"))

# Creating the column "month"
Gdata <- cbind(Gdata, "month" = format(as.Date(Gdata$date, "%d.%m.%Y"), "%m"))

# Creating a column, in which the month is written out
Gdata <- cbind(Gdata, "monat" = format(as.Date(Gdata$date, "%d.%m.%Y"), "%B"))

# Creating a column, in which for each day we define the day number within a year
# Here, the package "lubridate" is needed
library(lubridate)
Gdata <- cbind(Gdata, "day_nr" = yday(as.Date(Gdata$date, "%d.%m.%Y")))

# Sorting whole datatable by month
Gdata <- Gdata[order(Gdata$month),]
```


Also, for later `cast`-processing, we create a "value" column.

```{r, results='hide'}
# Creating the "value" column, which contains availability information (yes/no)
Gdata <- cbind(Gdata, "value" = 1)
```




Now that we organized the datatable for a bit, we are ready to create a first overview plot about how many individuals were trapped thoughout the years.

```{r, results='hide', fig.show='hide'}
# Creating a colour palette for the plot
colourpalette10 <- c("#596137",
                     "#BD57C7",
                     "#7FCD4E",
                     "#BF543A",
                     "#A3B1BF",
                     "#CFB253",
                     "#C55783",
                     "#4F3647",
                     "#7374BE",
                     "#84CAA0")

# Creating plot0. This plot shows the whole data (also NAs)!
# Here, the package "ggplot2" is needed
plotORIG <- ggplot(Gdata, aes(x = day_nr, fill = monat))+
  scale_fill_manual(name = "Month", values = colourpalette10,
                    breaks = c("Januar",
                               "Februar",
                               "März",
                               "April",
                               "Mai",
                               "Juni",
                               "Juli",
                               "August",
                               "September",
                               "Oktober"))+
  geom_histogram(binwidth = 1)+
  facet_wrap(site ~ year, ncol = 1)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Number of trapped individuals per site, including NAs",
       x = "Day of the year",
       y = "No of trapped Arctiinae individuals")+
  scale_x_continuous(expand = c(0,0),
                     breaks = seq(0, 365, 7),
                     limits = c(0, 365))
plotORIG
```


As we can see in this `plotORIG`, is does not make sense to include those data points, where we neither know the trapping site nor the trapping year.
So next, we delete those rows out of the datatable where this information is not noted. Further, we would like to have data rows with Arctiinae and 2nd trust level only. So we delete all other datapoints. Finally, as it does not make sense to keep them, we delete all rows where we do not know the species number.

```{r, results='hide'}
# Deleting all rows, where the taxon is not "Arct", the "spp" and "site" are not noted, the trust level is not "2" and where we dont have a specific trapping "year" noted
Gdata <- subset(Gdata, taxon == "Arct")
Gdata <- subset(Gdata, spp != "NA")
Gdata <- subset(Gdata, site != "NA")
Gdata <- subset(Gdata, trust == "2")
Gdata <- subset(Gdata, year != "NA")
Gdata <- droplevels(Gdata)
```

Now, we repeat plotting this. This plot includes all the datapoints that probably are more interesting to look at, as all basic information are given we need for further analyses and interpretation.

```{r, fig.cap='plot2', fig.ext='pdf', fig.height=27, fig.width=17, dpi=300}
# Creating overview_plot
# Here, the package "ggplot2" is needed
overview_plot <- ggplot(Gdata, aes(x = day_nr, fill = monat))+
  scale_fill_manual(name = "Month", values = colourpalette10,
                    breaks = c("Januar",
                               "Februar",
                               "März",
                               "April",
                               "Mai",
                               "Juni",
                               "Juli",
                               "August",
                               "September",
                               "Oktober"))+
  geom_histogram(binwidth = 1)+
  facet_wrap(site ~ year, ncol = 1)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Number of trapped Arctiinae individuals 2007-2015
       in EBN and 2010, 2013 & 2015 in Peru Panguana",
       x = "Day of the year",
       y = "No of trapped Arctiinae individuals")+
  scale_x_continuous(expand = c(0,0),
                     breaks = seq(0, 365, 7),
                     limits = c(0, 365))
overview_plot
```



## Transforming the data for further analyses

########### BRAUCHEN WIR DIES NOCH ?###########
Subsetting function bases

```{r, eval=FALSE}
# dataset_split <- function(data, light = FALSE, site = FALSE, trap = FALSE, month_start = "01", month_end = "12"){}

# sex_rowsplit <- function(data){}

# column_split <- function(data, light = FALSE, base_interval = "days"){}
```

```{r, eval=FALSE}
# subsetting(Gdata2, trap = "L", month_start = "05", month_end = "11")
```
########### BRAUCHEN WIR DIES NOCH ?###########



Transforming the datasets into the Pianka and Czekanowski input format.

`cast_EBN`
```{r, results='hide'}
# Creating a subset, which only contains data from EBN
Gdata_EBN <- subset(Gdata, site == "EBN")

# Creating a table in which we have relative values lateron
# For now using the Gdata_EBN dataset only
# Here, the package "reshape" is needed
cast_EBN <- cast(aggregate(Gdata_EBN$value,
                       by = list(Gdata_EBN$spp, Gdata_EBN$date),
                       FUN = "sum",
                       na.rm = T),
                  Group.1 ~ Group.2,
                  value = "x",
                  "sum")

# Changing the species to front column and deleting the species column
rownames(cast_EBN) <- cast_EBN$Group.1
cast_EBN <- cast_EBN[,-1]
```

`cast_PP`
```{r, results='hide'}
# Creating a subset, which only contains data from PP
Gdata_PP <- subset(Gdata, site == "PP")

# Creating a table in which we have relative values lateron
# For now using the Gdata_PP dataset only
# Here, the package "reshape" is needed
cast_PP <- cast(aggregate(Gdata_PP$value,
                       by = list(Gdata_PP$spp, Gdata_PP$date),
                       FUN = "sum",
                       na.rm = T),
                  Group.1 ~ Group.2,
                  value = "x",
                  "sum")

# Changing the species to front column and deleting the species column
rownames(cast_PP) <- cast_PP$Group.1
cast_PP <- cast_PP[,-1]
```

As function:
```{r}
# Gdata ==> cast_"site"
# package "reshape" is needed
cast_site <- function(data, site = "missing"){
  if("reshape" %in% rownames(installed.packages()) == FALSE) {install.packages("reshape")}
  library(reshape)
  if (site == "PP"){
    #subset, which only contains data from PP
    data_sub <- subset(data, site == "PP")}
  else
    if (site == "EBN"){
      #subset, which only contains data from EBN
      data_sub <- subset(data, site == "EBN")}
    else
      {return("Error: Please set site to EBN or PP")}
  #transforming the data into cast-format
  cast <- cast(aggregate(data_sub$value,
                       by = list(data_sub$spp, data_sub$date),
                       FUN = "sum",
                       na.rm = T),
                  Group.1 ~ Group.2,
                  value = "x",
                  "sum")
    #changing the species to front column and deleting the species column
    rownames(cast) <- cast$Group.1
    cast <- cast[,-1]
    return(cast)
}

cast_EBN <- cast_site(Gdata, site = "EBN")
cast_PP <- cast_site(Gdata, site = "PP")
```



### Running the Pianka and Czekanowski niche overlap probability for each site

For EBN.
```{r, results='hide'}
# Pianka and Czekanowski analysis for EBN

# Setting the input data
EBN <- cast_EBN/rowSums(cast_EBN)

# Pianka
EBN_P <- cbind(t(combn(rownames(EBN), 2)), 0)
    for (i in 1:nrow(EBN_P)) EBN_P[i, 3] <- sum(EBN[EBN_P[i, 
        1], ] * EBN[EBN_P[i, 2], ])/sqrt(sum(EBN[EBN_P[i, 1], 
        ]^2) * sum(EBN[EBN_P[i, 2], ]^2))
# Renaming columns
colnames(EBN_P) <- c("Spp1", "Spp2", "TempOverlapProb")

# Czekanowski
EBN_C <- cbind(t(combn(rownames(EBN), 2)), 0)
    for (i in 1:nrow(EBN_C)) EBN_C[i, 3] <- 1 - 0.5 * sum(abs((EBN[EBN_C[i, 
        1], ] - EBN[EBN_C[i, 2], ])))
# Renaming columns
colnames(EBN_C) <- c("Spp1", "Spp2", "TempOverlapProb")

# Creating an overview plot on the results
plot(EBN_P[,3], EBN_C[,3],
     main = "Niche Overlap Probabilities in EBN (2007-2015)",
     xlab =  "Pianka",
     ylab = "Czekanowski",
     pch = 3)
  mtext("(Each cross symbolizes one pair of species)")
  
# Setting target folder (Dropbox) as working directory
setwd("~/Dropbox/Co-occurrence/Results/Tables")

# Save results as tables
write.table(EBN_P, file = "nicheoverlap_observations_EBN_Pianka.txt",
            sep = "\t",
            row.names = F)
write.table(EBN_C, file = "nicheoverlap_observations_EBN_Czekanowski.txt",
            sep = "\t",
            row.names = F)

# Re-setting to process working directory
setwd("~/Studium/MSc/3. Semester/Temporal_niche_analyses/Git")
```

For PP.
```{r, results='hide'}
# Pianka and Czekanowski analysis for PP

# Setting the input data
PP <- cast_PP/rowSums(cast_PP)

# Pianka
PP_P <- cbind(t(combn(rownames(PP), 2)), 0)
    for (i in 1:nrow(PP_P)) PP_P[i, 3] <- sum(PP[PP_P[i, 
        1], ] * PP[PP_P[i, 2], ])/sqrt(sum(PP[PP_P[i, 1], 
        ]^2) * sum(PP[PP_P[i, 2], ]^2))
# Renaming columns
colnames(PP_P) <- c("Spp1", "Spp2", "TempOverlapProb")

# Czekanowski
PP_C <- cbind(t(combn(rownames(PP), 2)), 0)
    for (i in 1:nrow(PP_C)) PP_C[i, 3] <- 1 - 0.5 * sum(abs((PP[PP_C[i, 
        1], ] - PP[PP_C[i, 2], ])))
# Renaming columns
colnames(PP_C) <- c("Spp1", "Spp2", "TempOverlapProb")

# Creating an overview plot on the results
plot(PP_P[,3], PP_C[,3],
     main = "Niche Overlap Probabilities in Peru Panguana (2010/2013/2015)",
     xlab =  "Pianka",
     ylab = "Czekanowski",
     pch = 3)
  mtext("(Each cross symbolizes one pair of species)")
  
# Setting target folder (Dropbox) as working directory
setwd("~/Dropbox/Co-occurrence/Results/Tables")

# Save results as tables
write.table(PP_P, file = "nicheoverlap_observations_PP_Pianka.txt",
            sep = "\t",
            row.names = F)
write.table(PP_C, file = "nicheoverlap_observations_PP_Czekanowski.txt",
            sep = "\t",
            row.names = F)

# Re-setting to process working directory
setwd("~/Studium/MSc/3. Semester/Temporal_niche_analyses/Git")
```


Loading the results from original (observations) datasets:
```{r, results='hide'}
# Setting target folder (Dropbox) as working directory
setwd("~/Dropbox/Co-occurrence/Results/Tables")

# Re-load tables
EBN_p <- read.table("nicheoverlap_observations_EBN_Pianka.txt",
                   header = T,
                   sep = "\t")
EBN_c <- read.table("nicheoverlap_observations_EBN_Czekanowski.txt",
                   header = T,
                   sep = "\t")
PP_p <- read.table("nicheoverlap_observations_PP_Pianka.txt",
                   header = T,
                   sep = "\t")
PP_c <- read.table("nicheoverlap_observations_PP_Czekanowski.txt",
                   header = T,
                   sep = "\t")

# Re-setting to process working directory
setwd("~/Studium/MSc/3. Semester/Temporal_niche_analyses/Git")
```





```{r}
# get the species of the species pairs that show >= 0.75 overlap indicated by pianka index
#quant_PP_P <- quantile(PP_P$TempOverlapProb, 0.995)
spec5_PP_P1 <- PP_P$Spp1[PP_P$TempOverlapProb>=0.75]
spec5_PP_P2 <- PP_P$Spp2[PP_P$TempOverlapProb>=0.75]

#subset GData_PP to only include the species that are among the species pair that show the 5% highest niche overlap

## subset Gdata_PP
cast_PP_75 <- cast_PP[rownames(cast_PP) %in% spec5_PP_P1 | rownames(cast_PP) %in% spec5_PP_P2,]

## compare the amount of species in the raw and the subsetted dataset
nrow(cast_PP)
nrow(cast_PP_75)
nrow(cast_PP_75)/nrow(cast_PP)*100 #percentage of species remaining
choose(nrow(cast_PP_75),2)/choose(nrow(cast_PP),2)*100 #percentage of combinations remaining
```

As function:
```{r}
# get the species of the species pairs that show >=X prob overlap in the observations datasets
cast_site_prob <- function(data, prob = 0.50, site = "missing"){
  if(site %in% c("PP", "EBN")){
    #extracting the species from spp pairs prob >=X prob into single datasets
    sub_data_1 <- data$Spp1[data$TempOverlapProb >= prob]
    sub_data_2 <- data$Spp2[data$TempOverlapProb >= prob]
    #create one dataset with all the species just extracted
    if(site == "PP")
    {cast_prob <- cast_PP[rownames(cast_PP) %in% sub_data_1 | rownames(cast_PP) %in% sub_data_2,]
      return(cast_prob)}
    else
    {cast_prob <- cast_EBN[rownames(cast_EBN) %in% sub_data_1 | rownames(cast_EBN) %in% sub_data_2,]
      return(cast_prob)}}
  else
      {return("Error: Please set site to EBN or PP")}
}

# input data is the observation overlap result dataset of the particular site
cast_EBN_p_prob0.5 <- cast_site_prob(EBN_p, prob = 0.5, site = "EBN")
cast_EBN_c_prob0.5 <- cast_site_prob(EBN_c, prob = 0.5, site = "EBN")
cast_PP_p_prob <- cast_site_prob(PP_p, prob = X, site = "PP")
cast_PP_c_prob <- cast_site_prob(PP_c, prob = X, site = "PP")
```

```{r}
#compare the amount of species in the raw and the subsetted dataset
nrow(cast_EBN)
nrow(cast_EBN_p_prob0.5)
nrow(cast_EBN_p_prob0.5)/nrow(cast_EBN)*100 #percentage of species remaining
choose(nrow(cast_EBN_p_prob0.5),2)/choose(nrow(cast_EBN),2)*100 #percentage of combinations remaining
```



```{r}
#ra4 randomization
#modification of ra4 function {EcosimR} to avoid error msg
ra4_mod <- function(speciesData) {
    NonZeroRowShuffle <- function(vec = runif(10)) {
        nonzero <- which(vec > 0)
        shuffledvec <- vec
        shuffledvec[nonzero] <- vec[sample(nonzero, length(nonzero))] #mod: added length() to avoid error msg
        return(shuffledvec)
    }
    #split the dataset into rows which have more than one observation and rows that have only one
    data_mult_obs <- speciesData[rowSums(speciesData != 0) > 1,]
    data_solo_obs <- speciesData[rowSums(speciesData != 0) == 1,]
    RM <- t(apply(data_mult_obs, 1, NonZeroRowShuffle))
    rownames(RM) <- rownames(data_mult_obs)
    colnames(RM) <- colnames(data_solo_obs)
    RM <- rbind(RM, data_solo_obs)
    return(RM)
}

#write_txt function
organized_txt <- function(data_spp, method, site){
  if ("pianka" %in% list.files()|"czekanowski" %in% list.files())
    {}
  else
    {dir_list <- c("pianka", "czekanowski", "pianka/EBN", "pianka/PP", "czekanowski/EBN", "czekanowski/PP")
      for(i in dir_list){dir.create(i)}}
    colnames(data_spp) <- c("Spp1", "Spp2", (paste("Prob", 1:(ncol(data_spp)-2), sep = "_")))
    write.table(data_spp,
                file = paste(getwd(), "/", method, "/", site, "/", method,"_", site,"_", Sys.Date(), "_",
                             format(Sys.time(), "%H-%M"), ".txt", sep=""),
                sep = "\t",
                row.names = F)
    return(data_spp)
}

#temporal niche overlap analysis function
nicheoverlap <- function(data, method = "missing", ra4 = TRUE, iterations = 1, txt = FALSE, site = "missing"){
  if(site %in% c("PP", "EBN")){
    data_spp <- data.frame(Spp1 = factor(rep(1, choose(nrow(data), 2))),
                           Spp2 = factor(rep(1, choose(nrow(data), 2))))
    repeat{
      if(ra4 == TRUE){
        #ra4 randomization
        data_rand <- ra4_mod(data)
        #convert absolute to relative abundance data
        rel_data <- data_rand/rowSums(data_rand)}
      else {
          #convert absolute to relative abundance data
          rel_data <- data/rowSums(data)}
      if(method == "pianka"){
        # Pianka
        data_p <- cbind(t(combn(rownames(rel_data), 2)), 0)
        for (i in 1:nrow(data_p)){
          data_p[i, 3] <- sum(rel_data[data_p[i,1],] * rel_data[data_p[i,2],])/sqrt(sum(rel_data[data_p[i,1],]^2) * sum(rel_data[data_p[i, 2],]^2))
          }}
      else
      if(method == "czekanowski"){
        # Czekanowski
        data_p <- cbind(t(combn(rownames(rel_data), 2)), 0)
        for (i in 1:nrow(data_p)){
          data_p[i, 3] <- 1 - 0.5 * sum(abs((rel_data[data_p[i, 1], ] - rel_data[data_p[i, 2], ])))
        }}
      else
      {return("Error: Please set method as pianka or czekanowski")}
      data_spp[,c(1,2)] <- data_p[,c(1,2)]
      data_spp <- data.frame(data_spp, data_p[,3])
      if (ncol(data_spp)-2 == iterations[1]){break}
    }
    # write txt cut here
    if(txt == FALSE)
    {return(data_spp)}
    else
    {organized_txt(data_spp, method = method, site = site)}
    } else
      {return("Error: Please set site to EBN or PP")}
}

nicheoverlap_EBN_p <- nicheoverlap(cast_EBN_p_prob0.5, method = "pianka", ra4 = F, iterations = 10, txt = T, site = "EBN")
```

```{r}
#read in the results
readin <- function(site, method){
  file_list <- list.files(paste(getwd(), "/", method, "/", site, sep=""))
  #initialize empty dataframe
  data <- read.table(paste(getwd(), "/", method, "/", site, "/", file_list[1], sep=""), header = TRUE)
  for (i in file_list[-1]) {
    #read in the seperate files each indicated by the id number
    readin <- read.table(paste(getwd(), "/", method, "/", site, "/", i, sep=""), header = TRUE)
    #cbind the readin data into the dataframe data
    data <- cbind(data, readin[,3:ncol(readin)])
  }
  colnames(data) <- c("Spp1", "Spp2", (paste("Prob", 1:(ncol(data)-2), sep = "_")))
    return(data)
}
```

```{r}
#t-test power analysis
if("pwr" %in% rownames(installed.packages()) == FALSE) {install.packages("pwr")}
library(pwr)
#package pdf: https://cran.r-project.org/web/packages/pwr/pwr.pdf
```

```{r}
#t-test

```


- - - - - - - - - -
# Results

