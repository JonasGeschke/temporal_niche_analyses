---
title: "__Temporal Overlap Analyses of Tropical Arctiidae Species__"
author: "Jonas Geschke and Sören Greule"
date: "Winter semester 2015/16"
output:
  pdf_document:
    toc: yes
documentclass: article
classoption: a4paper
---



- - - - - - - - - -
# Introduction
_This skript is the outcome of a selected topic within the MSc Environmental Scienes, Faculty of Environment and Natural Resources, University of Freiburg. The selected topic is supervised by Dr Tim Burzlaff._

The script is about the analysis of monitoring data from both Costa Rica (locations: El Bosque Nuevo Butterfly Farm and the private home of P. Gloor, near San José) and Peru (location: Panguana). The main interest is about looking for existing temporal niche and community interactions within species of Arctiinae.



- - - - - - - - - -
# Methodology: Technical Thinking Process

1. co-occurrence approach => not really good results, need to specify actual research question and thereby subsettings of the data => WORKS NO
2. found paper (see below) => niche overlap approach

The main analysis approach comes from the paper "Temporal Overlap and Co-Occurrence in a Guild of Sub-Tropical Tephritid Fruit Flies" by Lopes GN, Souza-Filho MF, Gotelli NJ, Lemos LJU, Godoy WAC and Zucchi RA (2015) in PLoS ONE 10(7): e0132124, [doi:10.1371/journal.pone.0132124](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132124). We focus on their idea about the niche overlap analyses.

3. Pianka and Czekanowski => only indices, so edit of the background formular that it fits our needs => WORKS YES
4. ROSARIO: works with looping time periods (one year, one day) => we dont have proper data => WORKS NO
5. RA3: null-model approach, which randomized also the null values => transforms our data into pseudo-data => WORKS NO
6. RA4: null-model apporach, which fixes null values and randomizes the others => WORKS YES
7. Run XXX RA4 randomized datasheets for Pianka/Czekanowski analysis as null-model approach of our temporal overlap apporach
8. Tail probability analysis


The data used in our analyses come from the long-term monitoring trapping of the Chair of Forest Zoology and Entomology, University of Freiburg, and was undertaken by several staff members and student assistants.



# Steps within statistical analysis

1. Revising original data and re-organizing it for easier processing
2. Creating cast_"site" datasets as input for niche overlap analyses
    => cast_site function, input: Gdata
3. Run of observation datasets
    => RA4_nicheoverlap function, ra4 = FALSE, txt = FALSE, input: results of 2
4. Extracting the species with overlap probability of at least 0.75 in at least one spp pair
    => spppairs75prob function, input: reults of 3
5. Run of randomized datasets, only with 0.75prob species
    => RA4_nicheoverlap function, ra4 = TRUE, txt = TRUE, input: results of 4
6. Merge results, if needed
    => readin function, input: results of 5
7. Tail probability analysis



- - - - - - - - - -
# Script

## Defining general settings

To start the whole working process with the monitoring data and finally the statistical analyses, we first have to set the working directory. Also, we have to install and activate several R packages that are used in the following working process of the skript.

```{r packages, message=FALSE}
# Setting the working directory
# You might want to change the PFAD to your prefered saving location
setwd("~/Studium/MSc/3. Semester/Temporal_niche_analyses/Git")

# Installing  required packages, if they are not installed yet
if("devtools" %in% rownames(installed.packages())  == FALSE) {install.packages("devtools")}
if("lubridate" %in% rownames(installed.packages())  == FALSE) {install.packages("lubridate")}
if("ggplot2" %in% rownames(installed.packages())    == FALSE) {install.packages("ggplot2")}
if("reshape" %in% rownames(installed.packages())    == FALSE) {install.packages("reshape")}

# Loading the packages for the skript to work
library(devtools)
library(lubridate)
library(ggplot2)
library(reshape)

# Installing and loading our own NicheOverlapR packages, containing all functions needed for running this skript
install_github("NicheOverlapR", "JonasGeschke")
library(NicheOverlapR)
```


## Revising the original data

After setting the working directory and activating the required R packages, we read the data we want to work with. To always be sure to have a backup of the data, we directly create a second dataset `GdataORIG`, which is exactly the same as the one we already read in. Hopefully, we will never need this backup, but you never know what happens. As the last step in initially revising the monitoring data, we check the column names and - in case we cannot efficiently work with the given ones, change them for easier processing. `Gdata` from now on is data we work with.

```{r readin Gdata, results='hide'}
# Reading the original datatable
# For this, the file "IndID Auszug 01.Sep 15 All In.csv" has to be copied into the previously set working directory
Gdata <- read.csv2("IndID Auszug 01.Sep 15 All In.csv",
                   header = T,
                   sep = ";",
                   na.strings = "")

# Resaving the data a backup dataset
GdataORIG <- Gdata

# Checking the column names and changing them short and more efficient ones
names(Gdata)
colnames(Gdata) <- c("taxon",
                     "notes",
                     "light",
                     "spp",
                     "date",
                     "site",
                     "time",
                     "iid",
                     "sex",
                     "trap",
                     "trust")
names(Gdata)
```


With `Gdata`, we now have a dataser that we can further process very efficiently.
First of all, we already know we will not need the columns "notes" and "iid" (individual ID). Also, we check for oversight mistakes within the dataset.
From the monitoring, we have two levels of trust within the dataset: 1 and 2. Trust level "2" is good, level "1" not so much. The dataset also contains monitoring information with no trust level at all, which we delete at once, as we cannot be sure at all about their correctness in species identification.

```{r correcting oversight mistakes, results='hide'}
# Deleting the "notes" and "iid" columns
Gdata$notes <- NULL
Gdata$iid <- NULL
names(Gdata)

# Deleting the datapoints/rows, where no trust level is specified (= NA)
Gdata <- subset(Gdata, Gdata$trust != "NA")
Gdata <- Gdata[!is.na(Gdata$trust),]
Gdata <- droplevels(Gdata)
summary(Gdata)

# Correcting the "light" cells
summary(Gdata$light)
Gdata$light[Gdata$light == "atg"]           <- "tag"
Gdata$light[Gdata$light == "tag "]          <- "tag"
Gdata$light[Gdata$light == "nacht\n"]       <- "nacht"
Gdata$light[Gdata$light == "nachts"]        <- "nacht"
Gdata <- droplevels(Gdata)
summary(Gdata$light)
### There are further values we need to think about! ("m" and time)

# Correcting the "site" cells
summary(Gdata$site)
Gdata$site[Gdata$site == "CR"]              <- "EBN"
Gdata$site[Gdata$site == "EBN\n"]           <- "EBN"
Gdata$site[Gdata$site == "GLOOR"]           <- "PG"
Gdata <- droplevels(Gdata)
summary(Gdata$site)

# Correcting the "sex" cells
summary(Gdata$sex)
Gdata$sex[Gdata$sex == "f "]                <- "f"
Gdata$sex[Gdata$sex == "w"]                 <- "f"
Gdata <- droplevels(Gdata)
summary(Gdata$sex)
### There are further values we need to think about! ("?" and "f?")
```


## Processing the data for further uses

For getting first a first idea about the given monitoring data, we want to create an overview plot of the daily trapping success during the past years.
For such a plot, we need to sort the whole dataset by date. Thus, we add two columns - each one column for the year and for the month of the row. Two more columns are added containing the written month and the day number of the date within the whole year.

```{r cbind dates, results='hide'}
# Creating the column "year"
Gdata <- cbind(Gdata, "year" = format(as.Date(Gdata$date, "%d.%m.%Y"), "%Y"))

# Creating the column "month"
Gdata <- cbind(Gdata, "month" = format(as.Date(Gdata$date, "%d.%m.%Y"), "%m"))

# Creating the column, in which the month is written out
Gdata <- cbind(Gdata, "monat" = format(as.Date(Gdata$date, "%d.%m.%Y"), "%B"))

# Creating a column, in which we define the day number within the year
# Here, the package "lubridate" is needed
library(lubridate)
Gdata <- cbind(Gdata, "day_nr" = yday(as.Date(Gdata$date, "%d.%m.%Y")))

# Sorting whole datatable by month
Gdata <- Gdata[order(Gdata$month),]
```


Last but not least, we need to add another "value" column with a "1" in every row as presence information for each row defining one specimen being trapped. This is needed for later dataset transformations for the analyses.

```{r cbind value, results='hide'}
# Creating the "value" column, which contains presence information (1 = yes)
Gdata <- cbind(Gdata, "value" = 1)
```

Now, `Gdata` is a very nice organized and structured dataset we can work with during the whole following statistical process.



### Creating overview graphs of the monitoring/trapping success

We are ready to create a first overview plot about how many individuals were trapped thoughout the years.

```{r plotORIG, results='hide', fig.show='hide'}
# Creating a colour palette for the plot
# Here, the package "ggplot2" is needed
library(lubridate)
colourpalette10 <- c("#596137",
                     "#BD57C7",
                     "#7FCD4E",
                     "#BF543A",
                     "#A3B1BF",
                     "#CFB253",
                     "#C55783",
                     "#4F3647",
                     "#7374BE",
                     "#84CAA0")

# Creating plot0. This plot shows the whole data (also NAs)!
# Here, the package "ggplot2" is needed
plotORIG <- ggplot(Gdata, aes(x = day_nr, fill = monat))+
  scale_fill_manual(name = "Month", values = colourpalette10,
                    breaks = c("Januar",
                               "Februar",
                               "März",
                               "April",
                               "Mai",
                               "Juni",
                               "Juli",
                               "August",
                               "September",
                               "Oktober"))+
  geom_histogram(binwidth = 1)+
  facet_wrap(site ~ year, ncol = 1)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Number of trapped individuals per site, including NAs",
       x = "Day of the year",
       y = "No of trapped Arctiinae individuals")+
  scale_x_continuous(expand = c(0,0),
                     breaks = seq(0, 365, 7),
                     limits = c(0, 365))
plotORIG
```

As we can see in this `plotORIG`, is does not make any sense to include those data points we neither know the trapping site nor the trapping year. Thus, we delete those rows of the dataset this information is not given.
Due to the fact that this is the first try to get some niche overlap or cooccurrence information from the monitoring data, we want to keep the dataset as precise as possible for the moment. So we agreed to only analyse the taxon of Arctiinae and the 2nd trust level only. All other rows are deleted in the next step. Finally, as we cannot get any information out of those rows with no species identification number, we also drop those rows.

```{r subsetting, results='hide'}
# Deleting all rows, where the taxon is not "Arct", the "spp" and "site" are not given, the trust level is not "2" and where we do not have a specific trapping "year" noted
Gdata <- subset(Gdata, site != "NA")
Gdata <- subset(Gdata, year != "NA")
Gdata <- subset(Gdata, taxon == "Arct")
Gdata <- subset(Gdata, trust == "2")
Gdata <- subset(Gdata, spp != "NA")
Gdata <- droplevels(Gdata)
```


Now, we repeat plotting the cleaned monitoring data.
This `overview_plot` includes all the datapoints that probably are more interesting to look at, as all basic information are given we need for further analyses and interpretation.

You can see one graphical line per trapping site (EBN and PP) and year (for EBN 2007 to 2015 and for PP 2010, 2013 and 2015). On the x-axis, you can see the number of the day thoughout each year (1-365), devided into time periods of each one week. On the y acis, you can see the number of trapped Arctiinae individuals. As the graph displays the total number of individuals trapped per day, you cannot see any information regarding single species. Every month where trapping has taken place is marked in differnt colour, in order to easily distinguish between the months not only by day number but also directly within the graphical lines.

```{r overview_plot, fig.cap='plot2', fig.ext='pdf', fig.height=27, fig.width=17, dpi=300}
# Creating overview_plot
# Here, the package "ggplot2" is needed
library(lubridate)
overview_plot <- ggplot(Gdata, aes(x = day_nr, fill = monat))+
  scale_fill_manual(name = "Month", values = colourpalette10,
                    breaks = c("Januar",
                               "Februar",
                               "März",
                               "April",
                               "Mai",
                               "Juni",
                               "Juli",
                               "August",
                               "September",
                               "Oktober"))+
  geom_histogram(binwidth = 1)+
  facet_wrap(site ~ year, ncol = 1)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Number of trapped Arctiinae individuals 2007-2015
       in EBN and 2010, 2013 & 2015 in Peru Panguana",
       x = "Day of the year",
       y = "No of trapped Arctiinae individuals")+
  scale_x_continuous(expand = c(0,0),
                     breaks = seq(0, 365, 7),
                     limits = c(0, 365))
overview_plot
```



## Transforming the data for further analyses

For the final analyses of the dataset regarding temporal niche and cooccurrence interactions within the Arctiinae in EBN and PP, we need to transform the dataset.
Currently, the dataset consists out of a table with each row representing one trapped specimen. With the function `cast_site`, we transfer this table into each one new dataset per site, where each row represents not one specimen but one species and each column contains the presence information (1=yes, 0=no) for one trapping date.
Those datasets will be the input for the Pianka and Czekanowski analyses, two different niche overlap indices.

Now we can run the `cast_site` function contained in our NicheOverlapR package installed from Github and get one `cast_EBN` and one `cast_PP` dataset for further niche overlap analyses.

```{r run cast_site}
cast_EBN <- cast_site(Gdata, site = "EBN")
cast_PP <- cast_site(Gdata, site = "PP")
```



### Running the Pianka and Czekanowski niche overlap analyses for each site

For the main niche overlap analyses, we created a few functions for easy processing workflow.
So first, we load three functions:
• `ra4_mod`: RA4 randomization process as a modification of the RA4 function of the package "EcosimR"
• `organized_txt`: Automatic and organized saving of the analysis results
• `nicheoverlap`: Niche overlap function, based on the Pianka and Czekanowski indices

The first step within our analysis is to run the `nicheoverlap` function with the original monitoring data, in order to know the actually observed species pairs with their cooccurrence probability.
ATTENTION! Runnung these functions needs a lot of time due to very large size of the original input datasets. Thus, we saved the result tables as files and provide you with a read-in code, which you can find below.

```{r run observations nicheoverlap analyses}
EBN_p <- nicheoverlap(cast_EBN, method = "pianka", ra4 = FALSE, site = "EBN")
EBN_c <- nicheoverlap(cast_EBN, method = "czekanowski", ra4 = FALSE, site = "EBN")
PP_p <- nicheoverlap(cast_PP, method = "pianka", ra4 = FALSE, site = "PP")
PP_c <- nicheoverlap(cast_PP, method = "czekanowski", ra4 = FALSE, site = "PP")
```

As running the niche overlap analyses with the observed data needs quite some time, you can read the results with the following code block.

```{r read observation n.o. analyses results, results='hide'}
# Setting target folder (Dropbox) as working directory
setwd("~/Dropbox/Co-occurrence/Results/Tables")

# Reading the result tables
EBN_p <- read.table("nicheoverlap_observations_EBN_pianka.txt",
                   header = T,
                   sep = "\t")
EBN_c <- read.table("nicheoverlap_observations_EBN_czekanowski.txt",
                   header = T,
                   sep = "\t")
PP_p <- read.table("nicheoverlap_observations_PP_pianka.txt",
                   header = T,
                   sep = "\t")
PP_c <- read.table("nicheoverlap_observations_PP_czekanowski.txt",
                   header = T,
                   sep = "\t")

# Re-setting to process working directory
setwd("~/Studium/MSc/3. Semester/Temporal_niche_analyses/Git")
```


Due to the required processing time, we chose to reduce the size of the input data. We chose to only take those species for future analyses that are part of at least one species pair with an upper cooccurrence probability. Nevertheless, we tried to keep as many species within the analyes as possible.
Thus, we plotted the observation analysis results and chose a threshold value for future analyses. For EBN, we chose >=0.5 as the threshold value (57 species pairs, 79 single species within the Pianka and 20 single species within the Czekanowski analysis). For PP, we chose >=0.75 as the threshold value (240 species pairs, 152 single species within the Pianka and 103 single species within the Czekanowski analysis). In the following plots, you can see the species spairs of the total dataset (Czekanowski probability over Pianka probability), the species pairs for future analyses are marked in red.

```{r probabilities subsets EBN}
# Subsetting the results from the EBN pianka dataset, so only >=0.5 probability species pairs are in the future analyses (this subset is used for the followig plot!)
EBN_p_cut0.5 <- subset(EBN_p, TempOverlapProb >= 0.5)

# Creating the overview plot of the results
plot(EBN_p[,3], EBN_c[,3],
     main = "Niche Overlap Probabilities in EBN (2007-2015)",
     xlab =  "Pianka",
     ylab = "Czekanowski",
     pch = 3)
  mtext("(Each cross symbolizes one species pair, the red ones have prob >= 0.5)")
  abline(h = 0.5, v = 0.5, lty = 3, col = "grey")
  points(EBN_p_cut0.5[,3], 
         subset(EBN_c, rownames(EBN_c) %in% rownames(EBN_p_cut0.5))[,3], 
         pch = 3, 
         col = "red")
```

```{r probabilities subsets PP}
# Subsetting the results from the EBN pianka dataset, so only >=0.75 probability species pairs are in the future analyses (this subset is used for the followig plot!)
PP_p_cut0.75 <- subset(PP_p, TempOverlapProb >= 0.75)
 
# Creating the overview plot of the results
plot(PP_p[,3], PP_c[,3],
     main = "Niche Overlap Probabilities in Peru Panguana (2010/2013/2015)",
     xlab =  "Pianka",
     ylab = "Czekanowski",
     pch = 3)
  mtext("(Each cross symbolizes one species pair, the red ones have prob >= 0.75)")
  abline(h = 0.75, v = 0.75, lty = 3, col = "grey")
  points(PP_p_cut0.75[,3], 
         subset(PP_c, rownames(PP_c) %in% rownames(PP_p_cut0.75))[,3], 
         pch = 3, 
         col = "red")
```


Input data for RA4 analyses:

```{r run cast_site_prob}
# input data is the observation overlap result dataset of the particular site
cast_EBN_p_prob0.5 <- cast_site_prob(EBN_p, prob = 0.5, site = "EBN")
cast_EBN_c_prob0.5 <- cast_site_prob(EBN_c, prob = 0.5, site = "EBN")
cast_PP_p_prob0.75 <- cast_site_prob(PP_p, prob = 0.75, site = "PP")
cast_PP_c_prob0.75 <- cast_site_prob(PP_c, prob = 0.75, site = "PP")
```

```{r comparison cast datasets}
#compare the amount of species in the raw and the subsetted dataset
nrow(cast_EBN)
nrow(cast_EBN_p_prob0.5)
nrow(cast_EBN_p_prob0.5)/nrow(cast_EBN)*100 #percentage of species remaining
choose(nrow(cast_EBN_p_prob0.5),2)/choose(nrow(cast_EBN),2)*100 #percentage of combinations remaining
```

Subsetting by species pair:
```{r run subset_spppairs}
EBN_p_subset_perc95 <- subset_spppairs(EBN_p, percentile = 0.95)
EBN_c_subset_perc95 <- subset_spppairs(EBN_c, percentile = 0.95)
```



Running the nicheoverlap funtion as main RA4 analyses:

```{r run ra4 nicheoverlap analyses}
functiontest <- nicheoverlap(cast_EBN_p_prob0.5, method = "pianka", iterations = 2, txt = F, site = "EBN")
result_EBN_p_perc95_998 <- nicheoverlap(cast_EBN, EBN_p_subset_perc95, method = "pianka", iterations = 2, site = "EBN")
result_EBN_c_perc95_998 <- nicheoverlap(cast_EBN, EBN_c_subset_perc95, method = "czekanowski", iterations = 2, site = "PP")
```


Calculating the tail probabilty of the observed niche overlap.
```{r run tail_probability}
final_outcome_EBN_p <- tail_probability("EBN_p", "result_EBN_p_perc95")
```



```{r tail probaility explanation}
#create some randomly distributed data
set.seed(1)
x <-rnorm(1000)
#draw a histogramm of the data
hist(x,freq=FALSE)
#compute gaussian kernel density estimates and draw it as a line in the histogramm. kernel bandwidth = 
lines(dens <- density(x))
lines(dens <- density(x, bw = "SJ"), col = "blue" )

dens
lines( dens2 <- density(x, from = 1, n = 1000000),
       col="red", lwd = 2)
lines( dens3 <- density(x, to = 1, n = 1000000),
       col="blue", lwd = 2)
str(dens2)
#calculate the sum of the products of y-values and the x
with(dens2, sum(y * diff(x)[1]))+ with(dens3, sum(y * diff(x)[1]))
```




- - - - - - - - - -
# Results



- - - - - - - - - -
# Appendix

```{r cast_site function, eval=FALSE}
# This is the cast_"site" functionn for transforming the dataset to required input format
# As a function, the code block needs to be loaded once for running afterwards
cast_site <- function(data, site = "missing"){
  # Here, the package "reshape" is needed for the cast transformation
  if("reshape" %in% rownames(installed.packages()) == FALSE) {install.packages("reshape")}
  library(reshape)
  # Subsetting the dataset to only contain rows of the requested site
  if (site == "PP"){
    data_sub <- subset(data, site == "PP")}
  else
    if (site == "EBN"){
      data_sub <- subset(data, site == "EBN")}
    else
      {return("Error: Please set site to EBN or PP")}
  # Transforming the dataset into the described cast-format
  cast <- cast(aggregate(data_sub$value,
                       by = list(data_sub$spp, data_sub$date),
                       FUN = "sum",
                       na.rm = T),
                  Group.1 ~ Group.2,
                  value = "x",
                  "sum")
    # Changing the species identification information to the front column and
    rownames(cast) <- cast$Group.1
    # deleting the species column inside the table
    cast <- cast[,-1]
    return(cast)
}
```

```{r main niche overlap function, eval=FALSE}
# The RA4 randomization process as a modification of the
# RA4 function {EcosimR} to avoid upcoming error messages
# As a function, the code block needs to be loaded once for running afterwards
ra4_mod <- function(speciesData) {
    NonZeroRowShuffle <- function(vec = runif(10)) {
        nonzero <- which(vec > 0)
        shuffledvec <- vec
        shuffledvec[nonzero] <- vec[sample(nonzero, 
                                           length(nonzero))] #mod: added length() to avoid error msg
        return(shuffledvec)
    }
    #split the dataset into rows which have more than one observation and rows that have only one
    data_mult_obs <- speciesData[rowSums(speciesData != 0) > 1,]
    data_solo_obs <- speciesData[rowSums(speciesData != 0) == 1,]
    RM <- t(apply(data_mult_obs, 1, NonZeroRowShuffle))
    rownames(RM) <- rownames(data_mult_obs)
    colnames(RM) <- colnames(data_solo_obs)
    RM <- rbind(RM, data_solo_obs)
    return(RM)
}

# Function for organized automatic saving of our results
# As a function, the code block needs to be loaded once for running afterwards
organized_txt <- function(data_spp, method, site){
  if ("pianka" %in% list.files()|"czekanowski" %in% list.files())
    {}
  else
    {dir_list <- c("pianka", "czekanowski", "pianka/EBN", "pianka/PP", "czekanowski/EBN", "czekanowski/PP")
      for(i in dir_list){dir.create(i)}}
    colnames(data_spp) <- c("Spp1", "Spp2", (paste("Prob", 1:(ncol(data_spp)-2), sep = "_")))
    write.table(data_spp,
                file = paste(getwd(), "/", 
                             method, "/", 
                             site, "/", 
                             method,"_", 
                             site,"_", 
                             Sys.Date(), "_",
                             format(Sys.time(), "%H-%M"), 
                             ".txt", 
                             sep=""),
                sep = "\t",
                row.names = F)
    return(data_spp)
}

# Temporal niche overlap analysis function
# This is the main function for the Pianka and Czekanowski niche overlap analyses
# The Pianka and Czekanowski code is taken from the Package "EcoSimR"
# As a function, the code block needs to be loaded once for running afterwards
nicheoverlap <- function(data, subset = FALSE, method = "missing", ra4 = TRUE, iterations = 1, txt = FALSE, site = "missing"){
  if(site %in% c("PP", "EBN")){
    data_spp <- data.frame(Spp1 = factor(rep(1, choose(nrow(data), 2))),
                           Spp2 = factor(rep(1, choose(nrow(data), 2))))
    subset_paste <- apply(subset, 1, function(x) paste(x[1], x[2], sep ="_"))
    
    repeat{
      if(ra4 == TRUE){
        #ra4 randomization
        data_rand <- ra4_mod(data)
        #convert absolute to relative abundance data
        rel_data <- data_rand/rowSums(data_rand)}
      else {
          #convert absolute to relative abundance data
          rel_data <- data/rowSums(data)
          }
      comb <- t(combn(rownames(rel_data), 2))
      data_p <- cbind(comb, 998)
      if(subset == FALSE){
        row_iterator <- 1:nrow(data_p)}
        else {
          colnames(comb) <- c("Spp1", "Spp2")
          row_iterator <- which(complete.cases(merge(comb, cbind(subset, 1),
                                                     all.x = TRUE, by = c("Spp1", "Spp2"))))
          }
      if(method == "pianka"){
        # Pianka
        for (i in row_iterator){
          data_p[i, 3] <- sum(rel_data[data_p[i,1],] * rel_data[data_p[i,2],])/sqrt(sum(rel_data[data_p[i,1],]^2) * sum(rel_data[data_p[i, 2],]^2))
          }}
      else
      if(method == "czekanowski"){
        # Czekanowski
        for (i in row_iterator){
          data_p[i, 3] <- 1 - 0.5 * sum(abs((rel_data[data_p[i, 1], ] - rel_data[data_p[i, 2], ])))
        }}
      else
      {return("Error: Please set method as pianka or czekanowski")}
      data_spp[,c(1,2)] <- data_p[,c(1,2)]
      data_spp <- data.frame(data_spp, data_p[,3])
      if (ncol(data_spp)-2 == iterations[1]){break}
    }
    # organized_txt was cut here
    if(txt == FALSE)
    {return(data_spp)}
    else
    {organized_txt(data_spp, method = method, site = site)}
    } else
    {return("Error: Please set site to EBN or PP")}
}
```

```{r subset_spppairs function}
subset_spppairs <- function(data, percentile = FALSE, prob = FALSE){
  if(percentile == FALSE & prob != FALSE){
    subset <- data[data$TempOverlapProb >= prob, c(1, 2)]
    return(subset)
  }else{}
  if(prob == FALSE & percentile != FALSE){
    subset <- data[data$TempOverlapProb >= quantile(data$TempOverlapProb, percentile), c(1, 2)]
    return(subset)
  }else{}
  if(percentile != FALSE & prob != FALSE){return("Please only give input for either percentile or prob")}
  else {return("Please set either percentile or prob value")}
}
```

```{r cast_site_prob funtcion, eval=FALSE}
# get the species of the species pairs that show >=X prob overlap in the observations datasets
cast_site_prob <- function(data, prob = FALSE, percentile = FALSE, site = "missing"){
  if(site %in% c("PP", "EBN")){
    #extracting the species from spp pairs prob >=X prob into single datasets
    sub_data_1 <- data$Spp1[data$TempOverlapProb >= prob]
    sub_data_2 <- data$Spp2[data$TempOverlapProb >= prob]
    #create one dataset with all the species just extracted
    if(site == "PP")
    {cast_prob <- cast_PP[rownames(cast_PP) %in% sub_data_1 | rownames(cast_PP) %in% sub_data_2,]
      return(cast_prob)}
    else
    {cast_prob <- cast_EBN[rownames(cast_EBN) %in% sub_data_1 | rownames(cast_EBN) %in% sub_data_2,]
      return(cast_prob)}}
  else
      {return("Error: Please set site to EBN or PP")}
}
```

```{r readin_txt function, eval=FALSE}
#read in the results
readin_txt <- function(method, site){
  file_list <- list.files(paste(getwd(), "/", 
                                method, "/", 
                                site, 
                                sep=""))
  #initialize empty dataframe
  data <- read.table(paste(getwd(), "/", 
                           method, "/", 
                           site, "/", 
                           file_list[1], 
                           sep=""), 
                     header = TRUE)
  for (i in file_list[-1]) {
    #read in the seperate files each indicated by the id number
    readin <- read.table(paste(getwd(), "/", 
                               method, "/", 
                               site, "/", 
                               i, 
                               sep=""), 
                         header = TRUE)
    #cbind the readin data into the dataframe data
    data <- cbind(data, readin[,3:ncol(readin)])
  }
  colnames(data) <- c("Spp1", "Spp2", 
                      (paste("Prob", 1:(ncol(data)-2), sep = "_")))
    return(data)
}
```

```{r tail_probability function, eval=FALSE}
tail_probability <- function(observed_overlap, random_overlap){
        #right outer join by Spp1 and Spp2
        data <- merge(observed_overlap, random_overlap,
                      by = c("Spp1","Spp2"),
                      all.x = TRUE)
        #create empty dataframe for results
        results <- data.frame(Spp1 = vector(mode = "character"),
                              Spp2 = vector(mode = "character"),
                              Overlap = vector(mode = "numeric"),
                              Difference = vector(mode = "character"),
                              p_value = vector(mode = "numeric"),
                              No_of_RA4_probabilities = vector(mode = "numeric"),
                              No_of_RA4_iterations = vector(mode = "numeric"),
                              Percentage_of_analysed_species_pairs = vector(mode = "numeric"),
                              stringsAsFactors = F)
        # COMMENT
        for(i in 1:nrow(data)){
          if(is.na(data[i, 4])){
            results[nrow(results) + 1,] <- c(as.character(data[i, 1]),
                                             as.character(data[i, 2]),
                                             data[i, 3],
                                             NA, NA, NA, NA)
            }
          else
            {lower_dens <- density(as.numeric(data[i, 4:ncol(data)]),
                                   to = data[i, 3],
                                   n = 1000)
            upper_dens <- density(as.numeric(data[i, 4:ncol(data)]),
                                  from = data[i, 3],
                                  n = 1000)
            lower_tail_prob <- with(lower_dens, sum(y * diff(x)[1]))
            upper_tail_prob <- with(upper_dens, sum(y * diff(x)[1]))
            difference <- ifelse(lower_tail_prob > upper_tail_prob,
                                 "lower", "higher")
            p_value <- ifelse(lower_tail_prob < upper_tail_prob,
                              lower_tail_prob, upper_tail_prob)
            results[nrow(results) + 1,] <- c(as.character(data[i, 1]),
                                             as.character(data[i, 2]),
                                             data[i, 3],
                                             as.character(difference),
                                             signif(p_value, digits = 1),
                                             length(unique(c(data[i, 4:ncol(data)]))),
                                             (ncol(data)-3),
                                             sum(!is.na(data[, 4]))/nrow(data)*100)
          }
        }
        return(results)
}
```
